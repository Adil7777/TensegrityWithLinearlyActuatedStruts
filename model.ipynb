{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>A0</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.759297</td>\n",
       "      <td>0.419074</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>-0.759205</td>\n",
       "      <td>0.418863</td>\n",
       "      <td>3.39</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>-0.759242</td>\n",
       "      <td>0.419042</td>\n",
       "      <td>3.46</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>-0.759302</td>\n",
       "      <td>0.419248</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>-0.759177</td>\n",
       "      <td>0.418970</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y         Z    A0    A1   A2    A5    A6    A7\n",
       "0  0.000000 -0.759297  0.419074  3.31  2.01  0.0  1.94  1.58  1.65\n",
       "1  0.058824 -0.759205  0.418863  3.39  2.23  0.0  2.09  1.73  1.80\n",
       "2  0.117647 -0.759242  0.419042  3.46  2.16  0.0  2.09  1.80  1.87\n",
       "3  0.176471 -0.759302  0.419248  3.67  2.30  0.0  2.23  1.87  1.94\n",
       "4  0.235294 -0.759177  0.418970  3.82  2.30  0.0  2.16  1.87  1.94"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10708 entries, 0 to 10707\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   X       10708 non-null  float64\n",
      " 1   Y       10708 non-null  float64\n",
      " 2   Z       10708 non-null  float64\n",
      " 3   A0      10708 non-null  float64\n",
      " 4   A1      10708 non-null  float64\n",
      " 5   A2      10708 non-null  float64\n",
      " 6   A5      10708 non-null  float64\n",
      " 7   A6      10708 non-null  float64\n",
      " 8   A7      10708 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 753.0 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset[[\"X\", \"Y\", \"Z\"]], dataset[['A0', 'A1', 'A2', 'A5', 'A6', 'A7']]\n",
    "\n",
    "x_mean = X.iloc[:, 0].mean()\n",
    "\n",
    "x_std = X.iloc[:, 0].std()\n",
    "y_mean = X.iloc[:, 1].mean()\n",
    "y_std = X.iloc[:, 1].std()\n",
    "z_mean = X.iloc[:, 2].mean()\n",
    "z_std = X.iloc[:, 2].std()\n",
    "\n",
    "# Normalize each column\n",
    "X_norm = np.copy(X)\n",
    "X_norm[:, 0] = (X.iloc[:, 0] - x_mean) / x_std\n",
    "X_norm[:, 1] = (X.iloc[:, 1] - y_mean) / y_std\n",
    "X_norm[:, 2] = (X.iloc[:, 2] - z_mean) / z_std\n",
    "\n",
    "y_norm = y / 73.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = torch.tensor(pd.DataFrame(X_norm).values, dtype=torch.float32)\n",
    "y_norm = torch.tensor(pd.DataFrame(y_norm).values, dtype=torch.float32)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_norm, y_norm, test_size=0.2, shuffle=True, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9425,  0.6090,  1.6928],\n",
       "        [-0.7765,  1.6047,  0.8203],\n",
       "        [ 1.5648, -0.5537,  0.8535],\n",
       "        ...,\n",
       "        [-0.1568, -0.2147, -1.0535],\n",
       "        [-1.2321, -1.6867,  0.6647],\n",
       "        [ 0.6153,  0.3961,  0.7643]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "# Create loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearlyActuatedStruts(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearlyActuatedStruts, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(3, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 6),\n",
    "            nn.Sigmoid()  # Constrain to [0, 1]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 0.0700 | Val Loss: 0.0278\n",
      "Epoch 2/100 | Train Loss: 0.0189 | Val Loss: 0.0122\n",
      "Epoch 3/100 | Train Loss: 0.0102 | Val Loss: 0.0079\n",
      "Epoch 4/100 | Train Loss: 0.0069 | Val Loss: 0.0056\n",
      "Epoch 5/100 | Train Loss: 0.0035 | Val Loss: 0.0032\n",
      "Epoch 6/100 | Train Loss: 0.0025 | Val Loss: 0.0022\n",
      "Epoch 7/100 | Train Loss: 0.0021 | Val Loss: 0.0020\n",
      "Epoch 8/100 | Train Loss: 0.0018 | Val Loss: 0.0016\n",
      "Epoch 9/100 | Train Loss: 0.0016 | Val Loss: 0.0015\n",
      "Epoch 10/100 | Train Loss: 0.0015 | Val Loss: 0.0015\n",
      "Epoch 11/100 | Train Loss: 0.0014 | Val Loss: 0.0013\n",
      "Epoch 12/100 | Train Loss: 0.0012 | Val Loss: 0.0012\n",
      "Epoch 13/100 | Train Loss: 0.0013 | Val Loss: 0.0011\n",
      "Epoch 14/100 | Train Loss: 0.0010 | Val Loss: 0.0010\n",
      "Epoch 15/100 | Train Loss: 0.0010 | Val Loss: 0.0009\n",
      "Epoch 16/100 | Train Loss: 0.0009 | Val Loss: 0.0009\n",
      "Epoch 17/100 | Train Loss: 0.0009 | Val Loss: 0.0008\n",
      "Epoch 18/100 | Train Loss: 0.0009 | Val Loss: 0.0012\n",
      "Epoch 19/100 | Train Loss: 0.0009 | Val Loss: 0.0009\n",
      "Epoch 20/100 | Train Loss: 0.0008 | Val Loss: 0.0008\n",
      "Epoch 21/100 | Train Loss: 0.0008 | Val Loss: 0.0008\n",
      "Epoch 22/100 | Train Loss: 0.0008 | Val Loss: 0.0007\n",
      "Epoch 23/100 | Train Loss: 0.0008 | Val Loss: 0.0007\n",
      "Epoch 24/100 | Train Loss: 0.0007 | Val Loss: 0.0009\n",
      "Epoch 25/100 | Train Loss: 0.0006 | Val Loss: 0.0005\n",
      "Epoch 26/100 | Train Loss: 0.0007 | Val Loss: 0.0009\n",
      "Epoch 27/100 | Train Loss: 0.0007 | Val Loss: 0.0007\n",
      "Epoch 28/100 | Train Loss: 0.0006 | Val Loss: 0.0008\n",
      "Epoch 29/100 | Train Loss: 0.0006 | Val Loss: 0.0006\n",
      "Epoch 30/100 | Train Loss: 0.0006 | Val Loss: 0.0006\n",
      "Epoch 31/100 | Train Loss: 0.0006 | Val Loss: 0.0006\n",
      "Epoch 32/100 | Train Loss: 0.0006 | Val Loss: 0.0006\n",
      "Epoch 33/100 | Train Loss: 0.0006 | Val Loss: 0.0006\n",
      "Epoch 34/100 | Train Loss: 0.0006 | Val Loss: 0.0005\n",
      "Epoch 35/100 | Train Loss: 0.0005 | Val Loss: 0.0005\n",
      "Epoch 36/100 | Train Loss: 0.0005 | Val Loss: 0.0006\n",
      "Epoch 37/100 | Train Loss: 0.0005 | Val Loss: 0.0006\n",
      "Epoch 38/100 | Train Loss: 0.0006 | Val Loss: 0.0005\n",
      "Epoch 39/100 | Train Loss: 0.0005 | Val Loss: 0.0005\n",
      "Epoch 40/100 | Train Loss: 0.0005 | Val Loss: 0.0004\n",
      "Epoch 41/100 | Train Loss: 0.0005 | Val Loss: 0.0004\n",
      "Epoch 42/100 | Train Loss: 0.0005 | Val Loss: 0.0006\n",
      "Epoch 43/100 | Train Loss: 0.0004 | Val Loss: 0.0009\n",
      "Epoch 44/100 | Train Loss: 0.0005 | Val Loss: 0.0005\n",
      "Epoch 45/100 | Train Loss: 0.0005 | Val Loss: 0.0004\n",
      "Epoch 46/100 | Train Loss: 0.0004 | Val Loss: 0.0003\n",
      "Epoch 47/100 | Train Loss: 0.0005 | Val Loss: 0.0006\n",
      "Epoch 48/100 | Train Loss: 0.0004 | Val Loss: 0.0005\n",
      "Epoch 49/100 | Train Loss: 0.0005 | Val Loss: 0.0004\n",
      "Epoch 50/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 51/100 | Train Loss: 0.0004 | Val Loss: 0.0005\n",
      "Epoch 52/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 53/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 54/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 55/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 56/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 57/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 58/100 | Train Loss: 0.0004 | Val Loss: 0.0003\n",
      "Epoch 59/100 | Train Loss: 0.0004 | Val Loss: 0.0005\n",
      "Epoch 60/100 | Train Loss: 0.0003 | Val Loss: 0.0005\n",
      "Epoch 61/100 | Train Loss: 0.0004 | Val Loss: 0.0003\n",
      "Epoch 62/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 63/100 | Train Loss: 0.0004 | Val Loss: 0.0005\n",
      "Epoch 64/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 65/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 66/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 67/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 68/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 69/100 | Train Loss: 0.0004 | Val Loss: 0.0004\n",
      "Epoch 70/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 71/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 72/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 73/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 74/100 | Train Loss: 0.0004 | Val Loss: 0.0005\n",
      "Epoch 75/100 | Train Loss: 0.0004 | Val Loss: 0.0009\n",
      "Epoch 76/100 | Train Loss: 0.0003 | Val Loss: 0.0002\n",
      "Epoch 77/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 78/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 79/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 80/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 81/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 82/100 | Train Loss: 0.0003 | Val Loss: 0.0002\n",
      "Epoch 83/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 84/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 85/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 86/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 87/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 88/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 89/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 90/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 91/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 92/100 | Train Loss: 0.0003 | Val Loss: 0.0002\n",
      "Epoch 93/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 94/100 | Train Loss: 0.0003 | Val Loss: 0.0002\n",
      "Epoch 95/100 | Train Loss: 0.0003 | Val Loss: 0.0002\n",
      "Epoch 96/100 | Train Loss: 0.0003 | Val Loss: 0.0004\n",
      "Epoch 97/100 | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Epoch 98/100 | Train Loss: 0.0002 | Val Loss: 0.0003\n",
      "Epoch 99/100 | Train Loss: 0.0003 | Val Loss: 0.0002\n",
      "Epoch 100/100 | Train Loss: 0.0002 | Val Loss: 0.0002\n"
     ]
    }
   ],
   "source": [
    "model = LinearlyActuatedStruts()  # assuming you defined the class before\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "\n",
    "# Rescale predictions back to [0, 73.8]\n",
    "pred_real = predictions * 73.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.3800e+01, 7.3797e+01, 7.3800e+01, 9.6888e-01, 3.3849e-02, 6.7670e+01],\n",
      "        [4.3669e-04, 4.8995e-01, 5.9585e+01, 7.2945e-02, 4.8643e+01, 1.6026e-01],\n",
      "        [5.2107e+01, 3.0099e+01, 4.4288e-01, 1.5960e+01, 2.3254e+01, 2.2930e+01],\n",
      "        ...,\n",
      "        [7.3798e+01, 7.3641e+01, 7.3756e+01, 5.3089e+01, 1.0811e-01, 3.0853e-02],\n",
      "        [7.3783e+01, 7.3541e+01, 7.3793e+01, 2.5760e-01, 7.3597e+01, 5.3416e+01],\n",
      "        [7.3702e+01, 6.9238e+01, 8.5314e-03, 4.1192e+01, 6.5381e+01, 5.3757e+01]])\n"
     ]
    }
   ],
   "source": [
    "y_test_scaled = y_test * 73.8\n",
    "\n",
    "print(pred_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[73.4300, 73.3600, 73.2900,  0.0000,  0.0000, 69.4700],\n",
      "        [ 0.0000,  0.0000, 57.5600,  0.0000, 48.9800,  0.0000],\n",
      "        [49.2700, 28.4200,  0.0000, 16.8800, 24.0200, 23.3700],\n",
      "        ...,\n",
      "        [73.8000, 73.7200, 73.8000, 54.3900,  0.0000,  0.0000],\n",
      "        [73.8000, 73.8000, 73.8000,  0.0000, 73.8000, 54.6100],\n",
      "        [73.5800, 71.1300,  0.0000, 44.6500, 67.7400, 56.7000]])\n"
     ]
    }
   ],
   "source": [
    "print(y_test_scaled)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
